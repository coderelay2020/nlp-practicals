{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0dPqZKmyQIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Author :Ashutosh S Punyani\n",
        "'''\n",
        "\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qr_eSsu3QCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# load ascii text and covert to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spy-l8jq3-lV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDDDwFKD4bW4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0e9c0896-0a67-43c6-9241-e903fae15e1d"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print( \"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  164202\n",
            "Total Vocab:  65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLARuTVR4hnW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7585976-9363-468a-f28c-87d0ee654fdc"
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  164102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM5ZJxsh40ED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOkGeNGU5Hz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLYD2P75OKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY-T9xcZ5TbF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "befd5f56-64e1-4a7a-ffb1-3edf219f9244"
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 3.0202\n",
            "Epoch 00001: loss improved from inf to 3.02019, saving model to weights-improvement-01-3.0202.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 3.0202\n",
            "Epoch 2/20\n",
            "1280/1283 [============================>.] - ETA: 0s - loss: 2.8484\n",
            "Epoch 00002: loss improved from 3.02019 to 2.84829, saving model to weights-improvement-02-2.8483.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.8483\n",
            "Epoch 3/20\n",
            "1281/1283 [============================>.] - ETA: 0s - loss: 2.7675\n",
            "Epoch 00003: loss improved from 2.84829 to 2.76749, saving model to weights-improvement-03-2.7675.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.7675\n",
            "Epoch 4/20\n",
            "1281/1283 [============================>.] - ETA: 0s - loss: 2.7025\n",
            "Epoch 00004: loss improved from 2.76749 to 2.70247, saving model to weights-improvement-04-2.7025.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.7025\n",
            "Epoch 5/20\n",
            "1281/1283 [============================>.] - ETA: 0s - loss: 2.6459\n",
            "Epoch 00005: loss improved from 2.70247 to 2.64578, saving model to weights-improvement-05-2.6458.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.6458\n",
            "Epoch 6/20\n",
            "1281/1283 [============================>.] - ETA: 0s - loss: 2.5915\n",
            "Epoch 00006: loss improved from 2.64578 to 2.59151, saving model to weights-improvement-06-2.5915.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.5915\n",
            "Epoch 7/20\n",
            "1281/1283 [============================>.] - ETA: 0s - loss: 2.5405\n",
            "Epoch 00007: loss improved from 2.59151 to 2.54061, saving model to weights-improvement-07-2.5406.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.5406\n",
            "Epoch 8/20\n",
            "1280/1283 [============================>.] - ETA: 0s - loss: 2.4948\n",
            "Epoch 00008: loss improved from 2.54061 to 2.49459, saving model to weights-improvement-08-2.4946.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.4946\n",
            "Epoch 9/20\n",
            "1279/1283 [============================>.] - ETA: 0s - loss: 2.4520\n",
            "Epoch 00009: loss improved from 2.49459 to 2.45193, saving model to weights-improvement-09-2.4519.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.4519\n",
            "Epoch 10/20\n",
            "1280/1283 [============================>.] - ETA: 0s - loss: 2.4112\n",
            "Epoch 00010: loss improved from 2.45193 to 2.41130, saving model to weights-improvement-10-2.4113.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.4113\n",
            "Epoch 11/20\n",
            "1281/1283 [============================>.] - ETA: 0s - loss: 2.3737\n",
            "Epoch 00011: loss improved from 2.41130 to 2.37374, saving model to weights-improvement-11-2.3737.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.3737\n",
            "Epoch 12/20\n",
            "1281/1283 [============================>.] - ETA: 0s - loss: 2.3382\n",
            "Epoch 00012: loss improved from 2.37374 to 2.33826, saving model to weights-improvement-12-2.3383.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.3383\n",
            "Epoch 13/20\n",
            "1280/1283 [============================>.] - ETA: 0s - loss: 2.3057\n",
            "Epoch 00013: loss improved from 2.33826 to 2.30551, saving model to weights-improvement-13-2.3055.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.3055\n",
            "Epoch 14/20\n",
            "1281/1283 [============================>.] - ETA: 0s - loss: 2.2742\n",
            "Epoch 00014: loss improved from 2.30551 to 2.27420, saving model to weights-improvement-14-2.2742.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.2742\n",
            "Epoch 15/20\n",
            "1281/1283 [============================>.] - ETA: 0s - loss: 2.2437\n",
            "Epoch 00015: loss improved from 2.27420 to 2.24389, saving model to weights-improvement-15-2.2439.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.2439\n",
            "Epoch 16/20\n",
            "1281/1283 [============================>.] - ETA: 0s - loss: 2.2151\n",
            "Epoch 00016: loss improved from 2.24389 to 2.21497, saving model to weights-improvement-16-2.2150.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.2150\n",
            "Epoch 17/20\n",
            "1280/1283 [============================>.] - ETA: 0s - loss: 2.1866\n",
            "Epoch 00017: loss improved from 2.21497 to 2.18658, saving model to weights-improvement-17-2.1866.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.1866\n",
            "Epoch 18/20\n",
            "1281/1283 [============================>.] - ETA: 0s - loss: 2.1603\n",
            "Epoch 00018: loss improved from 2.18658 to 2.16021, saving model to weights-improvement-18-2.1602.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.1602\n",
            "Epoch 19/20\n",
            "1281/1283 [============================>.] - ETA: 0s - loss: 2.1359\n",
            "Epoch 00019: loss improved from 2.16021 to 2.13596, saving model to weights-improvement-19-2.1360.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.1360\n",
            "Epoch 20/20\n",
            "1281/1283 [============================>.] - ETA: 0s - loss: 2.1113\n",
            "Epoch 00020: loss improved from 2.13596 to 2.11126, saving model to weights-improvement-20-2.1113.hdf5\n",
            "1283/1283 [==============================] - 18s 14ms/step - loss: 2.1113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f97336e3860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo772QnY5X0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the network weights\n",
        "filename = \"weights-improvement-20-2.1113.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh5EKKT58n5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJoFJplV9RAI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7942a018-0269-4488-b766-375b92d186f1"
      },
      "source": [
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tprint(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" esting story,‚Äù but she could not\n",
            "help thinking there _must_ be more to come, so she sat still and sa \"\n",
            "e\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "h\n",
            "e\n",
            "r\n",
            " \n",
            "e\n",
            "e\n",
            "r\n",
            "e\n",
            " \n",
            "t\n",
            "h\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "t\n",
            "o\n",
            "r\n",
            "e\n",
            " \n",
            "w\n",
            "f\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "r\n",
            " \n",
            "t\n",
            "o\n",
            "e\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "o\n",
            "o\n",
            " \n",
            "t\n",
            "i\n",
            "e\n",
            "e\n",
            "l\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "r\n",
            " \n",
            "a\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "d\n",
            "l\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "n\n",
            "d\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "o\n",
            "e\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "o\n",
            "o\n",
            " \n",
            "t\n",
            "i\n",
            "e\n",
            "e\n",
            "l\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "r\n",
            " \n",
            "a\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "d\n",
            "l\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "n\n",
            "d\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "o\n",
            "e\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "o\n",
            "o\n",
            " \n",
            "t\n",
            "i\n",
            "e\n",
            "e\n",
            "l\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "r\n",
            " \n",
            "a\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "d\n",
            "l\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "n\n",
            "d\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "o\n",
            "e\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "o\n",
            "o\n",
            " \n",
            "t\n",
            "i\n",
            "e\n",
            "e\n",
            "l\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "r\n",
            " \n",
            "a\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "d\n",
            "l\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "n\n",
            "d\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "o\n",
            "e\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "o\n",
            "o\n",
            " \n",
            "t\n",
            "i\n",
            "e\n",
            "e\n",
            "l\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "r\n",
            " \n",
            "a\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "d\n",
            "l\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "n\n",
            "d\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "o\n",
            "e\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "o\n",
            "o\n",
            " \n",
            "t\n",
            "i\n",
            "e\n",
            "e\n",
            "l\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "r\n",
            " \n",
            "a\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "d\n",
            "l\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "n\n",
            "d\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "o\n",
            "e\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "o\n",
            "o\n",
            " \n",
            "t\n",
            "i\n",
            "e\n",
            "e\n",
            "l\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "r\n",
            " \n",
            "a\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "d\n",
            "l\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "n\n",
            "d\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "o\n",
            "e\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "o\n",
            "o\n",
            " \n",
            "t\n",
            "i\n",
            "e\n",
            "e\n",
            "l\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "r\n",
            " \n",
            "a\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "d\n",
            "l\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "n\n",
            "d\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "o\n",
            "e\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "o\n",
            "o\n",
            " \n",
            "t\n",
            "i\n",
            "e\n",
            "e\n",
            "l\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "r\n",
            " \n",
            "a\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "d\n",
            "l\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "n\n",
            "d\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "o\n",
            "e\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "o\n",
            "o\n",
            " \n",
            "t\n",
            "i\n",
            "e\n",
            "e\n",
            "l\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "r\n",
            " \n",
            "a\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "d\n",
            "l\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "n\n",
            "d\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "o\n",
            "e\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "o\n",
            "o\n",
            " \n",
            "t\n",
            "i\n",
            "e\n",
            "e\n",
            "l\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "e\n",
            "e\n",
            " \n",
            "h\n",
            "a\n",
            "r\n",
            " \n",
            "a\n",
            "n\n",
            " \n",
            "t\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PelCdWTa9XHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}